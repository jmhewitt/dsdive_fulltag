---
title: "Posterior diagnostics for model parameters"
output: 
  pdf_document: 
    toc: yes
header-includes:
  - \usepackage{booktabs}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, cache = FALSE)
```

```{r paths}
paths = list(
  # location of mcmc output files
  path_out = 'output/mcmc/nim_fit',
  # identifying characteristics of key output files
  active_samplers = 'nim_fit_active_samplers.rds',
  param_sample_pattern = 'nim_fit_parameter_samples_[0-9]+',
  param_sample_column_labels = 'nim_fit_parameter_samples_column_labels.rds'
)
```

```{r mcmc_input}
tar_load(nim_pkg)
```

```{r set_burn}
burn = 1:10
```

```{r parameter_groups}
# load targets of active samplers
active_samplers = unlist(readRDS(file.path(paths$path_out,
                                           paths$active_samplers)))

# identify common parameter names, excluding stages
parameter_families = setdiff(
  unique(gsub(pattern = '\\[.*\\]', replacement = '', x = active_samplers)),
  'stages'
)

# associate actively sampled targets with the common parameter names
sampler_groups = lapply(parameter_families, function(pfam) {
  grep(pattern = paste(pfam, '\\[', sep = ''), 
       x = active_samplers, value = TRUE)
})
names(sampler_groups) = parameter_families
sampler_groups = sampler_groups[order(names(sampler_groups))]

rm(active_samplers, parameter_families)
```

```{r output_files}
param_sample_files = dir(path = paths$path_out, 
                         pattern = paths$param_sample_pattern,
                         full.names = TRUE)

param_samples = do.call(rbind, lapply(param_sample_files, function(f) {
  readRDS(f)
}))

colnames(param_samples) = readRDS(file.path(paths$path_out, 
                                            paths$param_sample_column_labels))

rm(param_sample_files)
```


# Convergence diagnostics

## Traceplots

```{r scaled_trace_fn}
library(ggplot2)
library(ggthemes)
library(dplyr)
library(tidyr)

scaled_trace = function(samples, base_alpha = 1) {
  # Build a traceplot for a collection of variables by scaling/centering each
  # variable in samples.  The resulting plot overlays the scaled and centered 
  # traceplots in a single plot to let users quickly identify if there are any 
  # obvious non-convergence or mixing errors within the collection of variables
  # contained in samples.
  # 
  # Parameters:
  #  samples - matrix of MCMC samples, each row of which is output for one iter.
  
  df = data.frame(iter = 1:nrow(samples), scale(samples)) %>% 
    pivot_longer(cols = -iter, names_to = 'var', values_to = 'val')
  
  ggplot(df, aes(x = iter, y = val, group = var)) + 
    geom_hline(yintercept = 0) + 
    geom_line(alpha = base_alpha/sqrt(ncol(samples))) + 
    xlab('Iteration') + 
    ylab('Scaled parameter') +
    theme_few() + 
    theme(panel.border = element_blank())
}
```

```{r scaled_traces, fig.width=8, fig.height=3}
# prepare to use log-transformations for any variable with "var" in its title
# also return titles
transforms = lapply(names(sampler_groups), function(g) {
  if(grepl(pattern = 'var', x = g)) { c(tx = log, pre = 'log(', post = ')') } 
  else { c(tx = identity, pre = '', post = '') }
})

# plot group traceplots
invisible(mapply(
  function(g, name, tx) {
    print(
      scaled_trace(samples = tx$tx(param_samples[-burn, g, drop = FALSE]), 
                   base_alpha = .7) + 
        ggtitle(paste(tx$pre, name, tx$post, sep = ''))
    )
  }, 
  g = sampler_groups, 
  name = names(sampler_groups), 
  tx = transforms, 
  SIMPLIFY = FALSE
))
```

## Effective sample sizes

```{r ess_summary_plots}
library(coda)
invisible(mapply(
  function(g, name, tx) {
    plot(ecdf(effectiveSize(tx$tx(param_samples[-burn, g, drop = FALSE]))),
         xlab = 'Effective sample size', ylab = 'ECDF', 
         main = paste(tx$pre, name, tx$post, sep = ''))
  }, 
  g = sampler_groups, 
  name = names(sampler_groups), 
  tx = transforms, 
  SIMPLIFY = FALSE
))
```

```{r ess_table_alpha_mu}
# effective sizes (ESS's) for alpha_mu parameters
e = effectiveSize(param_samples[-burn, sampler_groups$alpha_mu])

# extract matrix index descriptions for parameters
arr_inds = do.call(rbind, lapply(names(e), function(tgt) {
  as.numeric(unlist(strsplit(gsub('[A-z\\[\\]]*', '', tgt), ',')))
}))

# initialize container to store ESS's with their parameter labels
m = nim_pkg$inits$alpha_mu * NA

# push ESS's into storage container
for(i in 1:nrow(arr_inds)) {
  m[arr_inds[i,1], arr_inds[i,2]] = e[i]
}

# remove unpopulated rows, and round ESS's to nearest integer
nz_rows = apply(m, 1, function(x) any(is.finite(x)))
nz_cols = apply(m, 2, function(x) any(is.finite(x)))
m = round(m[nz_rows, nz_cols])

# more compact printing
knitr::kable(t(m), digits = 0, caption = 'ESS for alpha_mu', booktabs = TRUE)
```

```{r ess_table_beta_mu}
# effective sizes (ESS's) for betas_tx_mu parameters
e = effectiveSize(param_samples[-burn, sampler_groups$beta_mu])

# extract matrix index descriptions for parameters
arr_inds = do.call(rbind, lapply(names(e), function(tgt) {
  as.numeric(unlist(strsplit(gsub('[A-z\\[\\]]*', '', tgt), ',')))
}))

# initialize container to store ESS's with their parameter labels
m = nim_pkg$inits$beta_mu * NA

# push ESS's into storage container
for(i in 1:nrow(arr_inds)) {
  m[arr_inds[i,1], arr_inds[i,2]] = e[i]
}

# remove unpopulated rows, and round ESS's to nearest integer
m = round(m[complete.cases(m),])

# more compact printing
knitr::kable(t(m), digits = 0, caption = 'ESS for beta_mu', booktabs = TRUE)
```

```{r ess_table_betas_tx_mu}
# effective sizes (ESS's) for betas_tx_mu parameters
e = effectiveSize(param_samples[-burn, sampler_groups$betas_tx_mu])

# extract matrix index descriptions for parameters
arr_inds = do.call(rbind, lapply(names(e), function(tgt) {
  as.numeric(unlist(strsplit(gsub('[A-z\\[\\]]*', '', tgt), ',')))
}))

# initialize container to store ESS's with their parameter labels
m = nim_pkg$inits$betas_tx_mu * NA

# push ESS's into storage container
for(i in 1:nrow(arr_inds)) {
  m[arr_inds[i,1], arr_inds[i,2]] = e[i]
}

# remove unpopulated rows, and round ESS's to nearest integer
m = round(m[complete.cases(m),])

# more compact printing
knitr::kable(t(m), digits = 0, booktabs = TRUE, caption = 'ESS for betas_tx_mu')
```


# Point estimates for population-level regression effects


```{r pt_ests_fn, fig.}
library(ggplot2)
library(ggthemes)
library(dplyr)
library(tidyr)

pt_ests = function(samples, dimnames) {
  # Parameters:
  #  samples - matrix of MCMC samples, each row of which is output for one iter.
  
  # extract matrix index descriptions for parameters
  arr_inds = do.call(rbind, lapply(colnames(samples), function(tgt) {
    as.numeric(unlist(strsplit(gsub('[A-z\\[\\]]*', '', tgt), ',')))
  }))
  
  # posterior HPDs for parameter estimates
  m = mcmc(samples)
  hpds = HPDinterval(m)
  
  # assemble posterior means and HPDs along with labels for parameters
  df = data.frame(
    param = factor(colnames(samples)),
    est = colMeans(m),
    lwr = hpds[,'lower'],
    upr = hpds[,'upper'],
    covariate = factor(dimnames[[1]][arr_inds[,1]]),
    attribute = factor(dimnames[[2]][arr_inds[,2]])
  )
  
  ggplot(df, aes(x = factor(attribute), y = est, ymin = lwr, ymax = upr)) + 
    geom_pointrange() +
    geom_hline(yintercept = 0, lty = 3) + 
    ylab('Regression effect') + 
    facet_wrap(~covariate, ncol = 1, scales = 'free_y', 
               strip.position = 'right') + 
    theme_few() + 
    theme(axis.title.y = element_blank(),
          panel.grid.major.y = element_line(color = 'grey90')) + 
    coord_flip()
}
```

```{r pt_ests, dependson='pt_ests_fn', fig.width=8, fig.height=8}
sub_groups = sampler_groups[sort(c('alpha_mu', 'beta_mu', 'betas_tx_mu', 
                                   'betas_tx_stage_offset'))]

colnames(nim_pkg$inits[['betas_tx_stage_offset']]) = names(tar_read(stages))
rownames(nim_pkg$inits[['betas_tx_stage_offset']]) = rownames(
  nim_pkg$data$covariates
)

invisible(mapply(
  function(g, name) {
    print(
      pt_ests(samples = param_samples[-burn, g, drop = FALSE], 
              dimnames = dimnames(nim_pkg$inits[[name]])) + 
        ggtitle(name)
    )
  }, 
  g = sub_groups, 
  name = names(sub_groups),
  SIMPLIFY = FALSE
))
```


# Exploring model issues

```{r shallow_ascents, eval = FALSE}
tgt_inds = which(
  nim_pkg$consts$betas_tx_stage_from == 
    nim_pkg$consts$ascent_like_stages['deep_ascent']
)
tgt = paste('betas_tx_mu[', nim_pkg$consts$intercept_covariate, ', ', tgt_inds,
            ']', sep = '')

colnames(nim_pkg$inits$betas_tx_mu)[tgt_inds]

plot(mcmc(param_samples[,tgt]))

# looks like the issue might be that 2 out of the 3 parameters are highly correlated
cor(mcmc(param_samples[,tgt]))


tgt_inds = which(
  nim_pkg$consts$betas_tx_stage_from == 
    nim_pkg$consts$ascent_like_stages['shallow_ascent']
)
tgt = paste('betas_tx_mu[', nim_pkg$consts$intercept_covariate, ', ', tgt_inds,
            ']', sep = '')

colnames(nim_pkg$inits$betas_tx_mu)[tgt_inds]

plot(mcmc(param_samples[,tgt]))

plot(mcmc(rowSums(param_samples[,tgt])))

x = rowSums(param_samples[,tgt])
plot(mcmc(x[x > -30]))

# looks like the issue might be that 2 out of the 3 parameters are highly correlated
cor(mcmc(param_samples[,tgt]))
```